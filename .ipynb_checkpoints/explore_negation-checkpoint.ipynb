{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy has some default rules for spliting text into sentences, as our text is already split\n",
    "# disabled this feature\n",
    "def prevent_sentence_boundary_detection(doc):\n",
    "    for token in doc:\n",
    "        # This will entirely disable spaCy's sentence detection\n",
    "        token.is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(prevent_sentence_boundary_detection, name='prevent-sbd', before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_bad_splits(parsed):\n",
    "    \"\"\" Default tokenizer splits over some or all '-'s do this as adding rules wasn't working\"\"\"\n",
    "    for token in parsed:\n",
    "        if re.fullmatch(r'[A-Z]', token.text) is not None:\n",
    "            i = token.i\n",
    "            if i == 0:\n",
    "                continue\n",
    "            with parsed.retokenize() as retokenizer:\n",
    "                retokenizer.merge(parsed[i-1:i+1])\n",
    "            return join_bad_splits(parsed)\n",
    "        if token.text == '-':\n",
    "            i = token.i\n",
    "            with parsed.retokenize() as retokenizer:\n",
    "                retokenizer.merge(parsed[i-1:i+2])\n",
    "            # Merging removes a token, so iterating over the list goes out of index    \n",
    "            return join_bad_splits(parsed)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ner_term(ner, token):\n",
    "    \"\"\" Check if the ner term matches the token, if there is punctuation in the ner,\n",
    "        check if it is a substring of the token\"\"\"\n",
    "    subtokens = re.split(r'[\\.\\,\\+\\*/-]', token)\n",
    "    ner_split = re.split(r'[\\.\\,\\+\\*/-]', token)\n",
    "    if len(ner_split) != 1:\n",
    "        return ner in token\n",
    "    return ner == token or ner in subtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ancestor_negation(gene, disease, doc):\n",
    "    \"\"\" Returns a list of booleans for whether each ancestor is negated in order from\n",
    "        root -> most common in parse tree.\"\"\"\n",
    "    gene_ancestors = []\n",
    "    dis_ancestors = []\n",
    "    # Get ancestors for each gene token\n",
    "    for token in doc:\n",
    "        if find_ner_term(gene, token.text):\n",
    "            # Need to reverse list an select the first before they are different\n",
    "            gene_ancestors.append([a.i for a in token.ancestors][::-1])\n",
    "        if find_ner_term(disease, token.text):\n",
    "            dis_ancestors.append([a.i for a in token.ancestors][::-1])\n",
    "    pairs = [(g,d) for g in gene_ancestors for d in dis_ancestors]\n",
    "    common_ancestors = []\n",
    "    for p in pairs:\n",
    "        common = []\n",
    "        for gene_ancestor, disease_ancestor in zip(p[0], p[1]):\n",
    "            if gene_ancestor == disease_ancestor:\n",
    "                common.append(disease_ancestor)   \n",
    "            # if they are different the trees diverge\n",
    "            else:\n",
    "                break\n",
    "        common_ancestors += common\n",
    "    common_ancestors = set(common_ancestors) # In case there are multiple pairs, shouldn't be anymore\n",
    "    negations = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'neg':\n",
    "            negations.append(token.head.i)\n",
    "    return [(c in negations) for c in common_ancestors] # Last term [:-1] is most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ner(x):\n",
    "    return x.upper().replace(' ', '_')\n",
    "\n",
    "data = pd.read_csv('../dataset/GAD_Y_N_wPubmedID_annotated_cap.csv', usecols=[2, 6, 9, 11], skiprows = [0],\n",
    "                   header=None, names=['rel', 'gene', 'disease', 'sentence'])\n",
    "\n",
    "data.gene = data.gene.apply(process_ner)\n",
    "data.disease = data.disease.apply(process_ner)\n",
    "data.rel = data.rel.apply(lambda x: x == 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for index, entry in data.iterrows():\n",
    "    docs.append(join_bad_splits(nlp(entry.sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True the results from this study indicate that polymorphisms in lrp and A2M are not associated with increased risk for AD in northern ireland. \n",
      "\n",
      "True False differences in physiological levels of MDR1 expression did not modify HIV-1 infection in vitro, nor did mdr1 alleles and haplotypes significantly influence either permissiveness to infection in vitro or disease progression in vivo before the initiation of treatment. \n",
      "\n",
      "False True these results suggest that polymorphisms of the ecnos gene, but not the ACE gene, may be associated with the development of LUNG_CANCER. \n",
      "\n",
      "False True genotype arg/arg, but not trp/arg, of the BETA(3)-ADRENERGIC_RECEPTOR was associated with both obesity and TYPE_2_DIABETES in a large japanese sample. \n",
      "\n",
      "False True this study shows that genetic variation of the AGT (m235t), but not the ace (i/d), genotypes contributes to the presence of CHD independently of blood pressure profile in a subset of the spanish population with a high prevalence of cardiovascular disease. \n",
      "\n",
      "False True although the AT2 gene has been reported to have a role in developmental anomalies of the kidney and ureter, our data indicate that it is not involved in the pathogenesis of primary familial VESICOURETERAL_REFLUX. \n",
      "\n",
      "30 6\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'neg'  present, detect 378 with most common word, detect 465 other wise\n",
    "i = 0\n",
    "j = 0\n",
    "for d, e in zip(docs[:100], data.iterrows()):\n",
    "    ancestors = common_ancestor(e[1].gene, e[1].disease, d)\n",
    "    shared = step_tree(e[1].disease, d) + step_tree(e[1].disease, d)\n",
    "    non_noun_neg = negated_ancestor_noun(d)\n",
    "    noun_approach = [s in non_noun_neg for s in shared]\n",
    "    if any([token.dep_ == 'neg' for token in d]):\n",
    "        i += 1\n",
    "        if any(ancestors) != any(noun_approach):\n",
    "            print(any(ancestors), any(noun_approach), e[1].sentence, '\\n')\n",
    "            j += 1\n",
    "print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negated_root(doc):\n",
    "    \"\"\" Returns whether the root node is negated in the document.\"\"\"\n",
    "    flag = False\n",
    "    for token in doc:    \n",
    "        if token.dep_ == 'neg' and token.head.dep_ == 'ROOT':\n",
    "            flag = not flag # Need to apply each itme the root is negated\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_presence(doc):\n",
    "    \"\"\" Returns whether there are any negation dependencies in the document.\"\"\"\n",
    "    return any([token.dep_ == 'neg' for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negated_noun_chunk(term, doc):\n",
    "    \"\"\" Returns wehther the noun chunk is negated. \"\"\"\n",
    "    for chunk in doc.noun_chunks:\n",
    "        print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp('based on these data, ABCB6 is not the causative gene for GRACILE_SYNDROME.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negated_ancestor_noun(doc):\n",
    "    \"\"\" Gives the indexes for the first ancestor of a negation word which is not a noun,\n",
    "        for all negations in a document\"\"\"\n",
    "    indexes = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'neg':\n",
    "            head = token.head\n",
    "            while head.dep_ != 'ROOT':\n",
    "                if head.pos_ == 'NOUN':\n",
    "                    head = head.head\n",
    "                else:\n",
    "                    indexes.append(head.i)\n",
    "                    break\n",
    "            if head.dep_ == 'ROOT':\n",
    "                indexes.append(head.i)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negated_ancestor_noun(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_tree(term, doc):\n",
    "    \"\"\" Gives the token indexes for the ancestors of a given term\"\"\"\n",
    "    indexes = []\n",
    "    for token in doc:\n",
    "        if token.text == term:\n",
    "            head = token\n",
    "            while head.dep_ != 'ROOT':\n",
    "                head = head.head\n",
    "                indexes.append(head.i)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negated_ancestor_noun(test) in step_tree('ACE', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 4, 18, 2]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_tree('ACE', test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
